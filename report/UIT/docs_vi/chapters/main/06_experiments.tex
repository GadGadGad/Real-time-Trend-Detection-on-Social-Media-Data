\section{Dữ liệu và Thiết lập Thực nghiệm}

\subsection{Nguồn Dữ liệu}
Hệ thống giám sát ba nguồn dữ liệu và thống nhất về một schema chung:
\begin{itemize}
    \item \textbf{Mạng xã hội (Facebook):} thu thập từ các fanpage tương tác cao (ví dụ: Theanh28, ThongTinChinhPhu). Trường chính gồm \texttt{pageName}, \texttt{postId}, \texttt{time} (ISO-8601), \texttt{text}, và các chỉ số tương tác (\texttt{likes}, \texttt{comments}, \texttt{shares}).
    \item \textbf{Tin tức chính thống:} crawl từ các nguồn đã xác minh (ví dụ: VnExpress, Tuổi Trẻ). Trường chính gồm \texttt{ArticleID}, \texttt{URL}, \texttt{Title}, \texttt{Content}, \texttt{PublishTime}.
    \item \textbf{Google Trends:} đóng vai trò \textbf{tín hiệu xác nhận/trễ} để xác thực và ưu tiên các cụm ứng viên phát hiện từ luồng xã hội.
\end{itemize}

Bộ dữ liệu thử nghiệm gồm \textbf{7.605 mục duy nhất} thu thập trong giai đoạn \textbf{08--22/12/2025}, gồm \textbf{4.644 bài báo} và \textbf{2.961 bài đăng mạng xã hội}. 
Sau khi trích xuất nội dung, \textbf{4.603 bài báo} có văn bản body hợp lệ và được dùng để tạo neo/embedding; \textbf{2.961} là số bài đăng xã hội \emph{duy nhất} dùng trong thử nghiệm sau khử trùng lặp và kiểm tra hợp lệ cơ bản.

\subsection{Phương pháp Thu thập Dữ liệu}
Chúng tôi sử dụng chiến lược thu thập lai kết hợp scraper tùy chỉnh và dịch vụ bên thứ ba:
\begin{itemize}
    \item \textbf{Tin tức chính thống:} scraper Python cho 5 báo lớn: VnExpress, Tuổi Trẻ, Thanh Niên, Người Lao Động, VietnamNet; trích xuất metadata và nội dung bài báo, có cơ chế retry và khử trùng lặp theo URL để crawl tăng dần. Các tác vụ được điều phối bằng Airflow và chạy theo lịch (mặc định: mỗi 6 giờ).
    \item \textbf{Mạng xã hội:} sử dụng Apify (Facebook Pages Scraper) để giám sát hơn 40 fanpage, trích xuất văn bản, dấu thời gian và tương tác (likes/comments/shares).
    \item \textbf{Google Trends:} lấy các truy vấn xu hướng thời gian thực cho Việt Nam qua unofficial Google Trends API wrapper để hỗ trợ xác nhận/trễ.
\end{itemize}

\begin{figure}[ht]
    \centering
    \scalebox{0.75}{
        % (giữ nguyên tikzpicture như bản gốc)
        \begin{tikzpicture}[
            node distance=0.8cm and 1.2cm,
            box/.style={rectangle, draw, rounded corners, minimum width=2cm, minimum height=0.8cm, align=center, font=\small},
            source/.style={box, fill=blue!20},
            process/.style={box, fill=orange!20},
            storage/.style={box, fill=green!20},
            arrow/.style={-{Stealth[scale=0.8]}, thick}
            ]
            \node[process] (airflow) {Airflow\\Scheduler};
            \node[source, right=1.5cm of airflow, yshift=1.6cm] (vne) {VnExpress};
            \node[source, right=1.5cm of airflow, yshift=0.8cm] (tt) {Tuổi Trẻ};
            \node[right=2.5cm of airflow, font=\large] (dots) {$\vdots$};
            \node[source, right=1.5cm of airflow, yshift=-0.8cm] (tn) {Thanh Niên};
            \node[source, right=1.5cm of airflow, yshift=-1.6cm] (nld) {NLD / VNN};

            \node[process, right=1.2cm of tt, yshift=-0.4cm] (workers) {Multi-Thread\\Workers};
            \node[process, right=1.2cm of workers] (extract) {HTML Parse\\+ Extract};
            \node[process, right=1.2cm of extract] (dedup) {Dedup\\Cache};
            \node[storage, right=1.2cm of dedup] (csv) {CSV / DB\\Storage};

            \draw[arrow] (airflow) -- (vne);
            \draw[arrow] (airflow) -- (tt);
            \draw[arrow] (airflow) -- (tn);
            \draw[arrow] (airflow) -- (nld);

            \draw[arrow] (vne) -- (workers);
            \draw[arrow] (tt) -- (workers);
            \draw[arrow] (tn) -- (workers);
            \draw[arrow] (nld) -- (workers);

            \draw[arrow] (workers) -- (extract);
            \draw[arrow] (extract) -- (dedup);
            \draw[arrow] (dedup) -- (csv);

            \draw[arrow, dashed] (extract.south) -- ++(0,-0.5) -| node[pos=0.25, below, font=\scriptsize] {Retry} (workers.south);
        \end{tikzpicture}
    }
    \caption{Pipeline Thu thập Bài báo Tin tức.}
    \label{fig:news_pipeline}
\end{figure}

\noindent Hình \ref{fig:news_pipeline} tóm tắt pipeline thu thập tin tức: Airflow điều phối theo lịch; scraper workers tải và trích xuất nội dung; hệ thống khử trùng lặp theo URL để crawl tăng dần; dữ liệu được lưu trữ để phục vụ các bước downstream.


\subsection{Phân tích Dữ liệu Khám phá}
Bảng \ref{tab:data_dist} trình bày phân phối bộ dữ liệu thử nghiệm. Chúng tôi quan sát thấy ``Khoảng cách Sẵn có'': dù crawl hơn $\approx 9.400$ URL tin tức, chỉ \textbf{4.603 bài báo (48,6\%)} có body trích xuất được; trong khi \textbf{bài đăng mạng xã hội (2.961 mục)} đạt mức sẵn có gần như hoàn toàn. Ngoài ra, hai nguồn có độ dài và phong cách khác biệt: bài báo thường $>500$ từ, còn bài đăng xã hội thường $<50$ từ và nhiều tiếng lóng. Sự phân đôi này thúc đẩy thiết kế hai đường xử lý: \textbf{Fast Path} cho văn bản ngắn tốc độ cao, và \textbf{Slow Path} tận dụng ngữ cảnh sâu từ neo tin tức.

\begin{table}
    \caption{Phân phối Dataset và Tính Sẵn có}\label{tab:data_dist}
    \centering
    \begin{tabular}{l c c c}
        \toprule
        \textbf{Loại Nguồn} & \textbf{URL Đã Crawl} & \textbf{Nội dung Hợp lệ} & \textbf{Độ dài TB (từ)} \\
        \midrule
        Tin tức Chính thống & $\approx 9.400$       & 4.603 (48,6\%)           & $> 500$                 \\
        Mạng Xã hội         & $\approx 3.000$       & 2.961 ($\approx 98,7\%$) & $< 50$                  \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Triển khai và Môi trường Vận hành}
Hệ thống được container hóa bằng \textbf{Docker Compose}. Các thành phần chính gồm Kafka, Spark, PostgreSQL và MongoDB; suy luận embedding sử dụng ONNX Runtime. Mục tiêu của cấu hình này là đảm bảo tính tái lập giữa môi trường demo và vận hành.


\subsubsection{Lợi ích Triển khai}
\begin{itemize}
    \item \textbf{Mở rộng độc lập:} tách thu nhập và xử lý giúp mở rộng theo tải.
    \item \textbf{Hiệu quả vận hành:} chỉ gọi LLM cho các cụm đã xác minh để giảm chi phí.
    \item \textbf{Tái lập:} môi trường được định nghĩa thống nhất bằng Docker Compose.
\end{itemize}

\subsection{Dataset Construction Strategy}
Để huấn luyện mô hình với chi phí gán nhãn thấp, chúng tôi dùng \textbf{Hybrid Labeling Strategy}:
\begin{enumerate}
    \item \textbf{Tự giám sát (Reranker):} khai thác hard negatives để tạo \textbf{877 cặp} chất lượng cao; reranker được dùng như thành phần khớp bổ trợ (xác minh/khôi phục) và module benchmark offline.
    \item \textbf{Học tích cực với LLM (Sentiment/Taxonomy):} dùng Gemini Pro gán nhãn giả khoảng \textbf{10k} mẫu, sau đó rà soát thủ công các điểm độ tin cậy thấp, thu được \textbf{4.630 mẫu Sentiment} và \textbf{3.687 mẫu Taxonomy} cho huấn luyện.
\end{enumerate}

\begin{figure}[htbp]
  \centering
  \begin{BVerbatim}[fontsize=\footnotesize,frame=single]
{"text": "Vụ xả súng tại bãi biển Bondi khiến 15 người thiệt mạng.",
 "label_sentiment": "Neutral", "label_taxonomy": "T1 - Crisis & Public Risk"}
{"text": ["Bão số 15 Koto đang ở đâu?", "Áp thấp nhiệt đới mạnh lên thành bão."],
 "label_relevance": 1.0}
  \end{BVerbatim}
  \caption{Ví dụ Dữ liệu Huấn luyện JSONL cho Phân loại và Reranking.}
  \label{fig:jsonl}
\end{figure}


\subsection{Lựa chọn Mô hình và Tinh chỉnh}
Chúng tôi tinh chỉnh các mô hình cụ thể cho tiếng Việt để phục vụ làm xương sống của hệ thống. Để đảm bảo tính mạnh mẽ, chúng tôi xây dựng một \textbf{Bộ Kiểm tra Stress} chứa 20 mẫu khó mỗi loại, đặc biệt nhắm vào các trường hợp biên như ``Tiếng lóng'' (ngôn ngữ mạng xã hội), ``Từ đồng nghĩa Bão'' (đặt tên sự kiện mơ hồ), và ``Chồng chéo Miền''. Bảng \ref{tab:training_config} chi tiết các siêu tham số huấn luyện cụ thể, và Bảng \ref{tab:models} hiển thị các metric hiệu suất cuối cùng trên bộ kiểm tra nghiêm ngặt này.

\begin{table}[htbp]
    \caption{Cấu hình Huấn luyện Chi tiết và Siêu tham số}
    \label{tab:training_config}
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l l l l}
            \toprule
            \textbf{Mục tiêu Mô hình} & \textbf{Kiến trúc Cơ sở} & \textbf{Kích thước Dataset} & \textbf{Cấu hình Huấn luyện} \\
            \midrule
            Sentiment & \texttt{uitnlp/visobert} & 4.630 (3 lớp) & Epochs: 20, Batch: 32, LR: 2e-5 \\
            Taxonomy  & \texttt{uitnlp/visobert} & 3.687 (7 lớp) & Epochs: 20, Batch: 16, LR: 2e-5 \\
            Reranker  & \texttt{ms-marco-MiniLM} & 877 cặp (Gold) & Contractive Loss, Epochs: 20 \\
            \bottomrule
        \end{tabular}
    }
\end{table}


\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/embedding_benchmark.png}
    \caption{Kết quả benchmark so sánh các Mô hình Embedding trên các trường hợp biên khác nhau.} \label{fig:benchmark}
\end{figure}



Hình \ref{fig:benchmark} so sánh độ ổn định (khoảng cách giữa cặp dương/âm) của 5 mô hình tiên tiến nhất. Chúng tôi định nghĩa Khoảng cách Ổn định theo toán học như:
\begin{equation}
    Gap = Sim(q, pos) - Sim(q, neg)
\end{equation}
\texttt{vietnamese-document-embedding} (thanh xanh) duy trì biên độ lớn nhất nhất quán trên các trường hợp biên như ``Từ đồng nghĩa Bão'' và ``Tiếng lóng'', xác nhận việc lựa chọn nó làm mô hình xương sống của chúng tôi.

Kết quả cho thấy \texttt{dangvantuan/vietnamese-document-embedding} đạt độ ổn định tốt nhất (Gap Trung bình 0,265). Bảng \ref{tab:embedding_benchmark} chi tiết hiệu suất trên các thách thức ngôn ngữ cụ thể, được định nghĩa như sau:

\begin{itemize}
    \item \textbf{Gap Trung bình:} Biên độ ổn định trung bình trên tất cả các trường hợp kiểm tra.
    \item \textbf{Bão:} Khả năng nhóm các tên bão đa dạng (ví dụ: ``Bão Yagi'', ``Bão số 3'').
    \item \textbf{Miền:} Truy xuất chéo miền (ví dụ: khớp truy vấn ``Y tế'' với bài đăng ``Bệnh viện'').
    \item \textbf{Danh mục:} Phân biệt giữa các loại sự kiện (ví dụ: ``Lũ lụt'' vs. ``Kẹt xe'').
    \item \textbf{Tiếng lóng:} Xử lý teen-code và tiếng lóng internet Việt Nam (ví dụ: ``bão'' vs ``b4o'').
    \item \textbf{Viết tắt:} Giải quyết các viết tắt phổ biến (ví dụ: ``HCM'' $\rightarrow$ ``Thành phố Hồ Chí Minh'').
\end{itemize}

\textbf{Phân tích:} Trong khi \texttt{vn-sbert} xuất sắc ở các nhiệm vụ nặng từ khóa như nhóm ``Bão'' (Gap: 0,355), nó thất bại hoàn toàn ở ``Tiếng lóng'' (-0,005), chỉ ra rằng nó coi tiếng lóng là nhiễu. Ngược lại, \texttt{vn-doc-embedding} duy trì hiệu suất mạnh mẽ trên ``Tiếng lóng'' (0,283) và ``Viết tắt'' (0,419), làm cho nó trở thành lựa chọn ưu việt để xử lý văn bản mạng xã hội thô nơi ngôn ngữ không chính thức phổ biến.

\begin{table}
    \caption{Embedding Stability Gap Analysis (Metric: Cosine Distance Diff)}\label{tab:embedding_benchmark}
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l c c c c c c}
            \toprule
            \textbf{Model Identifier}                   & \textbf{Avg Gap} $\uparrow$ & \textbf{Storm} $\uparrow$ & \textbf{Domain} $\uparrow$ & \textbf{Category} $\uparrow$ & \textbf{Slang}  $\uparrow$ & \textbf{Abbrev}  $\uparrow$ \\
            \midrule
            \textbf{vn-doc-embedding*} \cite{ref_vndoc} & \textbf{0.265}              & 0.239                     & 0.224                      & \textbf{0.162}               & \textbf{0.283}             & \textbf{0.419}              \\
            vn-bi-encoder                               & 0.193                       & 0.155                     & 0.213                      & 0.107                        & 0.108                      & 0.381                       \\
            vn-sbert \cite{ref_visobert}                & 0.188                       & \textbf{0.355}            & 0.172                      & 0.033                        & -0.005                     & 0.386                       \\
            bge-m3 \cite{ref_bge}                       & 0.160                       & -0.003                    & \textbf{0.269}             & 0.070                        & 0.192                      & 0.273                       \\
            multilingual-e5 \cite{ref_e5}               & 0.058                       & 0.018                     & 0.088                      & 0.022                        & 0.073                      & 0.091                       \\
            \bottomrule
        \end{tabular}%
    }
\end{table}

\begin{table}
    \caption{Hiệu suất Mô hình Đã Tinh chỉnh}\label{tab:models}
    \centering
    \begin{tabular}{l l c c}
        \toprule
        \textbf{Nhiệm vụ Mô hình} & \textbf{Loại Lớp}   & \textbf{Độ chính xác} ($\uparrow$) & \textbf{Độ trễ} ($\downarrow$) \\
        \midrule
        Bộ phân loại Sentiment    & 3 lớp (Pos/Neg/Neu) & \textbf{93,5\%}                    & 12ms                           \\
        Bi-CrossEncoder Reranker  & Xếp hạng Relevance  & 91,0\%                             & 45ms                           \\
        Bộ phân loại Taxonomy     & 7 lớp (T1-T7)       & 89,2\%                             & 14ms                           \\
        \bottomrule
    \end{tabular}
\end{table}
