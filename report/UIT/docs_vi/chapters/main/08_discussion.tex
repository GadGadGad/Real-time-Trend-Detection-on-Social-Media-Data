\section{Thảo luận}

\subsection{Thách thức và Bài học Rút ra}
Triển khai hệ thống đã bộc lộ ba trở ngại kỹ thuật chính:
\begin{enumerate}
    \item \textbf{Sự mơ hồ Ngữ nghĩa:} Các cộng đồng khác nhau sử dụng các thuật ngữ khác nhau cho cùng một sự kiện (ví dụ: ``Bão Yagi'' vs. ``Cơn bão số 3''). Chúng tôi giải quyết vấn đề này bằng \textbf{LLM-based Deduplication} (Phụ lục Bảng \autoref{tab:prompt_dedup}) và điểm Hybrid Matching.
    \item \textbf{Khoảng trống Đánh giá:} Việc thiếu nhãn ground truth trong dữ liệu luồng gây khó khăn cho việc xác thực. Chúng tôi vượt qua bằng cách thiết lập giao thức \textbf{``Mini-Ground Truth''} (gán nhãn thủ công 300 mẫu) để chuẩn hóa các chỉ số NMI và F1.
    \item \textbf{Đánh đổi Độ trễ vs. Độ chính xác:} Gọi LLM cho mỗi cụm tạo ra độ trễ 2-3s. Chúng tôi giảm thiểu bằng cách tách pipeline thành \textbf{Fast Path} (Spark) cho phát hiện tức thì và \textbf{Slow Path} (Async Workers) cho phân tích sâu. Ngoài ra, chúng tôi triển khai \textbf{Quy tắc Cập nhật Tăng dần}: LLM chỉ được kích hoạt lại nếu cụm tăng $>20\%$ về khối lượng, giảm đáng kể chi phí suy luận dư thừa.
\end{enumerate}

\subsection{Cân nhắc Đạo đức và Hạn chế}
Với tư cách là một hệ thống tích hợp AI phân tích diễn ngôn công cộng, chúng tôi tuân theo các thực hành dữ liệu đạo đức và thừa nhận rõ ràng các hạn chế chính:
\begin{itemize}
    \item \textbf{Bảo vệ Quyền riêng tư:} Mặc dù hệ thống xử lý các bài đăng công khai, chúng tôi che giấu Thông tin Nhận dạng Cá nhân (PII) như số điện thoại và địa chỉ cụ thể trước khi lưu trữ. Chúng tôi trình bày kết quả ở cấp \emph{cụm/sự kiện} để tránh nhắm vào cá nhân.
    \item \textbf{Thiên lệch và Phạm vi Nguồn:} Các ``neo'' tin tức có thể phản ánh thiên lệch biên tập hoặc phạm vi không đầy đủ. Để giảm thiểu, pipeline hỗ trợ rõ ràng khám phá sự kiện \textbf{Chỉ-Xã-hội} (qua HDBSCAN) để các chủ đề ít được đưa tin vẫn có thể xuất hiện; tuy nhiên, lựa chọn neo có thể ảnh hưởng đến những gì trở thành ``đã xác minh'' trong các tóm tắt hạ nguồn.
    \item \textbf{An toàn và Độ tin cậy của LLM:} LLMs có thể tạo các tóm tắt có vẻ hợp lý nhưng không chính xác. Do đó, chúng tôi hạn chế việc sử dụng LLM vào \emph{làm giàu hậu kỳ} (không kích hoạt phát hiện) và áp dụng chính sách xác minh \textbf{Human-in-the-Loop} cho các cảnh báo rủi ro cao (T1--Khủng hoảng) trước khi leo thang bên ngoài.
\end{itemize}

\subsection{Hàm ý Thiết kế từ Nghiên cứu Khử}
Kết quả nghiên cứu khử (\autoref{tab:ablation}) cho thấy hệ thống chỉ đạt hiệu quả khi các thành phần được phối hợp đầy đủ.
Các \textbf{News Anchors} đóng vai trò then chốt trong việc ổn định phân cụm trước dữ liệu xã hội nhiễu; \textbf{Heuristic Guard} giúp kiểm soát nhiễu đầu vào và ngăn bùng nổ cụm không có ý nghĩa; trong khi \textbf{LLM Refinement} là yếu tố quyết định khả năng diễn giải của sự kiện.
Những quan sát này củng cố lựa chọn thiết kế pipeline nhiều tầng, trong đó các bộ lọc nhẹ và phân cụm nhanh được ưu tiên ở giai đoạn phát hiện, còn LLM được sử dụng có chọn lọc cho làm giàu ngữ nghĩa hậu kỳ.


