\section{Công trình Liên quan}
Phát hiện sự kiện từ mạng xã hội đã tiến triển từ các phương pháp dựa trên thống kê/từ khóa sang các phương pháp dựa trên biểu diễn ngữ nghĩa (embedding) và gần đây là các hệ thống tăng cường bằng Mô hình Ngôn ngữ Lớn (LLM).
Trong báo cáo này, chúng tôi phân loại các công trình liên quan thành bốn hướng: (1) thống kê truyền thống, (2) neural/embedding kết hợp phân cụm, (3) LLM và Tạo sinh Tăng cường Truy xuất (RAG), và (4) kiến trúc luồng thời gian thực. \autoref{tab:related_work} tổng hợp so sánh các đại diện tiêu biểu theo các tiêu chí: mức độ hiểu ngữ nghĩa, khả năng thời gian thực, xử lý nhiễu, tính diễn giải và khả năng mở rộng.

\subsection{Thống kê truyền thống}
Các phương pháp ban đầu dựa trên tần suất và mô hình hóa chủ đề, điển hình như \textbf{TF-IDF/BM25} \cite{ref_bm25}, \textbf{LDA} \cite{ref_lda} và \textbf{EDCoW} \cite{ref_edcow}.
Nhìn chung, nhóm này có ưu điểm về chi phí tính toán thấp và dễ mở rộng, phù hợp thông lượng cao.
Tuy nhiên, chúng thường kém hiệu quả với văn bản mạng xã hội ngắn và nhiễu, đồng thời không nắm bắt được tương đồng ngữ nghĩa giữa các cách diễn đạt khác nhau (ví dụ: cùng một sự kiện nhưng khác từ vựng).

\subsection{Neural/Embedding và phân cụm}
Sự phát triển của học sâu cho phép biểu diễn ngữ nghĩa giàu hơn thông qua các mô hình như \textbf{BERT} \cite{ref_bert} và biến thể tối ưu cho tương đồng câu như \textbf{SBERT} \cite{ref_sbert}.
Một số hướng tiêu biểu kết hợp embedding với phân cụm, chẳng hạn \textbf{BERTopic} \cite{ref_bertopic} (embedding transformer + HDBSCAN + TF-IDF theo lớp).
Về phân cụm, \textbf{K-Means} \cite{ref_kmeans} yêu cầu chọn trước số cụm và khó xử lý nhiễu; \textbf{DBSCAN} \cite{ref_dbscan} có thể phát hiện cụm theo mật độ và gán điểm nhiễu nhưng nhạy với ngưỡng toàn cục; \textbf{HDBSCAN} \cite{ref_hdbscan} mở rộng DBSCAN theo mật độ phân cấp, phù hợp hơn cho dữ liệu mạng xã hội với mật độ tương tác thay đổi.
Nhóm neural/embedding cải thiện rõ rệt khả năng gom cụm theo ngữ nghĩa và xử lý biến đổi từ vựng, nhưng đổi lại là chi phí suy luận và độ nhạy siêu tham số, gây khó khăn khi triển khai thời gian thực ở quy mô lớn.

\subsection{LLM và Tạo sinh Tăng cường Truy xuất (RAG)}
LLMs gần đây (ví dụ GPT-4, Gemini, Claude) cho thấy khả năng suy luận và tóm tắt mạnh \cite{ref_llm_reasoning}, nhưng dễ gặp \emph{ảo giác} nếu thiếu ngữ cảnh kiểm chứng.
\textbf{RAG} \cite{ref_rag} khắc phục bằng cách điều kiện hóa phản hồi của LLM trên tài liệu/điểm dữ liệu được truy xuất, giúp tăng độ bám sát thực tế trong tóm tắt sự kiện.
Trong bối cảnh phát hiện sự kiện, LLM/RAG đặc biệt hữu ích cho việc \emph{làm giàu ngữ nghĩa} (tóm tắt, trích xuất thông tin dạng 5W1H), song chi phí suy luận cao khiến việc đặt LLM trực tiếp trên đường phát hiện thời gian thực thường không khả thi.

\subsection{Kiến trúc luồng thời gian thực}
Các hệ thống thời gian thực thường ưu tiên cân bằng thông lượng--độ trễ--độ chính xác.
Một số công trình sớm như \textbf{Sakaki et al.} \cite{ref_twitter_earthquake} cho thấy tính khả thi của phát hiện sự kiện từ Twitter theo thời gian thực; các hướng hệ thống như \textbf{TwitterNews+} \cite{ref_streaming_survey} kết hợp phân cụm tăng dần và các đặc trưng nhẹ để đạt độ trễ thấp.
Về hạ tầng, các thiết kế phổ biến dựa trên \textbf{Lambda} hoặc \textbf{Kappa}, sử dụng message broker (Kafka) và engine xử lý luồng (Spark/Flink) để mở rộng ngang.
Điểm hạn chế thường gặp là các pipeline luồng giảm chiều sâu ngữ nghĩa để đổi lấy tốc độ, khiến kết quả ít diễn giải hoặc kém nhất quán khi dữ liệu nhiễu.

\subsection{Khoảng trống nghiên cứu và hướng tiếp cận của chúng tôi}
Tổng hợp từ \autoref{tab:related_work}, có một đánh đổi phổ biến: các phương pháp đạt \emph{độ trễ thấp} thường dựa vào đặc trưng nhẹ và thiếu nhất quán ngữ nghĩa; ngược lại, các phương pháp dùng LLM đạt \emph{diễn giải/hiểu ngữ nghĩa} tốt nhưng khó đáp ứng yêu cầu thời gian thực do chi phí suy luận.
Công trình của chúng tôi nhắm đến khoảng trống này bằng cách tách rời phát hiện nhanh khỏi làm giàu ngữ nghĩa: \textbf{Dual-Path Architecture} kết hợp phân cụm nhanh (SAHC trên Fast Path) và làm giàu hậu kỳ bằng LLM (Slow Path) để đạt thời gian thực mà vẫn đảm bảo khả năng diễn giải.
Ngoài ra, chúng tôi sử dụng \textbf{LLM-as-a-Judge} để hỗ trợ đánh giá trong bối cảnh thiếu nhãn ground-truth, phù hợp với kịch bản dữ liệu luồng.

% --- GIỮ NGUYÊN BẢNG HIỆN CÓ ---
\begin{table}[H]
    \caption{So sánh các Phương pháp Phát hiện Sự kiện}\label{tab:related_work}
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l c c c c c}
            \toprule
            \textbf{Approach}                        & \textbf{Semantic}      & \textbf{Real-time}  & \textbf{Noise}      & \textbf{Interpretable} & \textbf{Scalable}   \\
                                                     & \textbf{Understanding} & \textbf{Capable}    & \textbf{Handling}   & \textbf{Output}        &                     \\
            \midrule
            TF-IDF / BM25 \cite{ref_bm25}            & Low                    & \checkmark          & Limited             & --                     & \checkmark          \\
            LDA \cite{ref_lda}                       & Medium                 & --                  & Limited             & \checkmark             & \checkmark          \\
            EDCoW \cite{ref_edcow}                   & Low                    & \checkmark          & Limited             & --                     & \checkmark          \\
            BERT + Clustering \cite{ref_bert}        & High                   & --                  & Medium              & --                     & --                  \\
            BERTopic \cite{ref_bertopic}             & High                   & --                  & \checkmark          & \checkmark             & --                  \\
            TwitterNews+ \cite{ref_streaming_survey} & Medium                 & \checkmark          & Medium              & --                     & \checkmark          \\
            \midrule
            \textbf{Ours (SAHC + LLM)}               & \textbf{High}          & \textbf{\checkmark} & \textbf{\checkmark} & \textbf{\checkmark}    & \textbf{\checkmark} \\
            \bottomrule
        \end{tabular}%
    }
\end{table}
