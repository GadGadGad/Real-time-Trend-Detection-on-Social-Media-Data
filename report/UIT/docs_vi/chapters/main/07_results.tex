\section{Kết quả và Phân tích}

\subsection{Lựa chọn Thuật toán Phân cụm}
Chúng tôi so sánh phương pháp SAHC của chúng tôi (sử dụng lõi HDBSCAN) với các baselines. HDBSCAN được chọn vì khả năng xử lý Nhiễu và Cân bằng vượt trội.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/trend_tsne.png}
    \caption{Trực quan hóa t-SNE của các Cụm Sự kiện. Các màu đại diện cho các sự kiện riêng biệt được cô lập bởi thuật toán.} \label{fig:tsne}
\end{figure}

Phiếu chiếu t-SNE trong \autoref{fig:tsne} chứng minh hiệu quả của phân cụm của chúng tôi. Các sự kiện riêng biệt (các cụm màu) được phân tách tốt trong không gian ngữ nghĩa, trong khi các điểm nhiễu (xám) phân tán và được cô lập hiệu quả bởi thuật toán.

\begin{table}[htbp]
    \caption{So sánh Phương pháp Phân cụm}
    \label{tab:clustering_select}
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l c c c c c}
            \toprule
            \textbf{Phương pháp}          & \textbf{Cụm (k)} & \textbf{Điểm Nhiễu} & \textbf{Silh. Score} ($\uparrow$) & \textbf{DB Index} ($\downarrow$) & \textbf{Thời gian} ($\downarrow$) \\
            \midrule
            K-Means                       & 253              & 0                   & 0,024                             & 3,177                            & 8,45s                             \\
            \textbf{HDBSCAN (Baseline)}   & \textbf{460}     & 1.984               & 0,109                             & \textbf{2,094}                   & 16,00s                            \\
            BERTopic                      & 223              & 1.801               & 0,112                             & 2,363                            & 55,72s                            \\
            \textbf{SAHC (Của chúng tôi)} & \textbf{315}     & \textbf{985}        & \textbf{0,135}                    & \textbf{1,951}                   & \textbf{18,4s}                    \\
            \bottomrule
        \end{tabular}
    }
\end{table}


\textbf{Phân tích:} Như hiển thị trong \autoref{tab:clustering_select}, \textbf{K-Means} cho thấy không phù hợp với dữ liệu luồng xã hội vì nó ép tất cả nhiễu vào các cụm. \textbf{HDBSCAN Baseline}, trong khi xác định đúng nhiễu, chịu \textbf{phân mảnh quá mức} (460 cụm) và loại bỏ dữ liệu quá nhiều (1.984 điểm nhiễu), thường chia các sự kiện đơn lẻ thành nhiều micro-cụm.
Phương pháp \textbf{SAHC} của chúng tôi giải quyết điều này bằng cách sử dụng News Anchors để ``nối'' các micro-cụm này. Điều này thành công cô đặc không gian thành \textbf{315 sự kiện mạch lạc} và khôi phục $\approx 50\%$ dữ liệu hợp lệ trước đó bị loại bỏ là nhiễu (Nhiễu giảm xuống 985), tăng đáng kể Silhouette Score lên \textbf{0,135}.

\subsection{Đánh giá Định lượng (Mini-Ground Truth)}
Tất cả các metric phân cụm dựa trên nhãn (NMI, Purity, BCubed-F1, Entropy) được tính toán chỉ trên tập con Mini-Ground Truth (N=300), vì bộ dữ liệu đầy đủ không chứa nhãn sự kiện do con người chú thích.
\autoref{tab:minigt} báo cáo hiệu suất của \textbf{cài đặt SAHC mặc định}, trong khi \autoref{tab:ablation} cho thấy thêm rằng \textbf{pipeline hybrid đầy đủ} (thêm anchoring và tinh chỉnh LLM) cải thiện NMI từ 0,54 lên \textbf{0,5978}.

\begin{table}
    \caption{Hiệu suất trên Mini-Ground Truth (N=300) -- Cài đặt SAHC Cơ sở}\label{tab:minigt}
    \centering
    \begin{tabular}{l c l}
        \toprule
        \textbf{Metric}           & \textbf{Giá trị} & \textbf{Diễn giải}                         \\
        \midrule
        \textbf{NMI} ($\uparrow$) & \textbf{0,54}    & Thông tin tương hỗ tốt với nhãn người      \\
        Purity ($\uparrow$)       & 0,65             & Tính nhất quán lớp chiếm ưu thế cao        \\
        BCubed-F1 ($\uparrow$)    & 0,35             & Precision/recall cân bằng cho phân cụm     \\
        Entropy ($\downarrow$)    & 4,85             & Entropy thấp hơn chỉ ra cụm tinh khiết hơn \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Định nghĩa Metric (tóm tắt):} Chúng tôi sử dụng các metric bao phủ nhiều khía cạnh của chất lượng phân cụm, gồm \textbf{NMI, Purity, Entropy, BCubed-F1} (tính trên Mini-Ground Truth) và \textbf{Silhouette Score} (đánh giá mức độ tách biệt nội cụm/liên cụm).
Các định nghĩa và công thức chi tiết được trình bày trong \textbf{Phụ lục B}.

\subsection{Đánh giá Batch và Phân tích Thành phần}
Để lượng hóa đóng góp của mỗi module, chúng tôi tiến hành nghiên cứu ablation trên tập con \textbf{Mini-Ground Truth} (N=300), nơi các metric dựa trên nhãn (NMI, BCubed-F1, Entropy) được định nghĩa tốt.
\autoref{tab:ablation} cho thấy việc thêm dần anchoring và tinh chỉnh LLM cải thiện sự phù hợp phân cụm với nhãn người.

\begin{table}
    \caption{Nghiên cứu Ablation trên Mini-Ground Truth (N=300)}\label{tab:ablation}
    \centering
    \begin{tabular}{l c c c}
        \toprule
        \textbf{Cấu hình}               & \textbf{NMI} ($\uparrow$) & \textbf{BCubed-F1} ($\uparrow$) & \textbf{Entropy} ($\downarrow$) \\
        \midrule
        Baseline (Chỉ HDBSCAN)          & 0,53                      & 0,31                            & 4,91                            \\
        \textbf{Pipeline Hybrid Đầy đủ} & \textbf{0,5978}           & \textbf{0,3821}                 & \textbf{4,4178}                 \\
        \quad w/o News Anchors          & 0,48                      & 0,27                            & 5,12                            \\
        \quad w/o Heuristic Guard       & 0,41                      & 0,15                            & 5,68                            \\
        \quad w/o Tinh chỉnh LLM        & 0,54                      & 0,33                            & 4,85                            \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Phân tích Định tính: LLM-làm-Giám-khảo}
Các metric truyền thống như Silhouette Score thường không nắm bắt được tính mạch lạc ngữ nghĩa. Để giải quyết điều này, nhóm triển khai giao thức \textbf{LLM-làm-Giám-khảo}, nơi một mô hình instruction-tuned mạnh (Gemini Pro) hoạt động như proxy cho đánh giá của con người.
\begin{enumerate}
    \item \textbf{Pairwise Coherence Assessment (So sánh cặp):}
          \begin{itemize}
              \item \textbf{Cơ chế:} Đưa 2 cluster (A và B) cho LLM và hỏi \textit{``Cụm nào có nội dung mạch lạc hơn?''}.
              \item \textbf{Metric:} \textbf{Win-Rate} (Tỷ lệ thắng). Giúp loại bỏ bias khi chấm điểm tuyệt đối.
          \end{itemize}
    \item \textbf{Topic Consistency Verification (Kiểm tra nhất quán):}
          \begin{itemize}
              \item \textbf{Bước 1:} LLM suy luận ``Chủ đề chung'' từ 5 bài viết mẫu.
              \item \textbf{Bước 2:} LLM chấm điểm từng bài viết dựa trên chủ đề đó (Relevant/Irrelevant).
              \item \textbf{Metric:} \textbf{Weighted Consistency Score} (0,0 - 1,0).
          \end{itemize}
\end{enumerate}

\textbf{Ưu điểm:} Phương pháp này đánh giá được ngữ nghĩa sâu (Semantic) mà các metrics toán học như Silhouette không thể hiện hết được.

Sử dụng framework này, chúng tôi đánh giá một tập mẫu các cụm sự kiện. Kết quả (Sample Run) được trình bày trong \autoref{tab:llm_qualitative}.

\begin{table}[htbp]
    \caption{Kết quả Đánh giá LLM Thực tế (Qualitative Results)}
    \label{tab:llm_qualitative}
    \centering
    \resizebox{0.85\textwidth}{!}{%
        \begin{tabular}{p{5.0cm} c p{3.0cm} c}
            \toprule
            \textbf{Nội dung Cụm (Rút dọn)}            & \textbf{Win-Rate} & \textbf{Chủ đề Suy luận} & \textbf{Consistency} \\
            \midrule
            Putin tuyên bố `Bao Vây' Ukraine           & \textbf{0,67}     & Chiến sự Nga-Ukraine     & \textbf{1,00}        \\
            Thỏa thuận ngừng bắn Israel-Hamas          & \textbf{0,67}     & Xung đột Trung Đông      & \textbf{0,96}        \\
            Thời trang nữ: Boho, Vintage               & 0,67              & Thời trang \& Style      & 0,97                 \\
            Sạt lở đất gây hậu quả nghiêm trọng        & 0,67              & Thiên tai \& Bão lũ      & 1,00                 \\
            \midrule
            Việt kiều kiện tụng \& xung đột lãnh thổ   & \textbf{0,00}     & Tin tức quốc tế (Mixed)  & \textbf{0,64}        \\
            {[}Noise{]} Không đủ thông tin tạo tiêu đề & 0,00              & Rác / Lỗi thu thập       & N/A                  \\
            \bottomrule
        \end{tabular}%
    }
\end{table}

\textbf{Nhận xét:}
\begin{itemize}
    \item Cụm sự kiện rõ ràng (Chiến sự, Thiên tai) đạt điểm tuyệt đối (\textbf{Consistency $\approx$ 1,0}).
    \item Cụm bị trộn lẫn (Mixed) có điểm thấp (\textbf{0,64}) và Win-Rate = 0, cho thấy LLM phát hiện lỗi phân cụm tốt.
\end{itemize}

\subsection{Nghiên cứu Trường hợp Chi tiết}
Để hiểu rõ hơn hành vi của hệ thống, chúng tôi phân tích ba trường hợp cụ thể từ triển khai thử nghiệm:

\begin{enumerate}
    \item \textbf{Trường hợp Thành công: ``Vụ xả súng Bãi biển Bondi'' (T1).}
          \begin{itemize}
              \item \emph{Đầu vào:} ``{\fontencoding{T5}\selectfont Vụ xả súng tại bãi biển Bondi khiến 15 người thiệt mạng sau vụ tấn công bằng dao.}''
              \item \emph{Phân tích:} Mặc dù tin tức đồng thời về ``Du lịch Úc'', thuật toán SAHC đã cô lập đúng sự kiện này do trùng lặp từ vựng mạnh với các từ khóa ``Khủng hoảng''. LLM gán nó vào \textbf{T1 (Rủi ro Công cộng)} với độ tin cậy cao (>0,9).
          \end{itemize}

    \item \textbf{Trường hợp Thành công: ``Xung đột Trung Đông'' (T1).}
          \begin{itemize}
              \item \emph{Metrics:} Cụm này đạt điểm Tính Nhất quán Ngữ nghĩa \textbf{0,96} và Tỷ lệ Thắng \textbf{0,67} so với các cụm nhiễu.
              \item \emph{Insight:} Khối lượng lớn các neo tin tức đã xác minh cho phép hệ thống hấp thụ phản ứng mạng xã hội hiệu quả mà không ``trôi'' vào các chủ đề không liên quan.
          \end{itemize}

    \item \textbf{Phân tích Thất bại: ``Tin Quốc tế Hỗn hợp''.}
          \begin{itemize}
              \item \emph{Vấn đề:} Thuật toán gộp ``Vụ kiện gốc Việt'' với ``Xung đột lãnh thổ'' thành một cụm duy nhất.
              \item \emph{Nguyên nhân Gốc:} Điều này có thể xảy ra do thuật ngữ ngoại giao chung (ví dụ: ``chủ quyền'', ``luật quốc tế'') hoạt động như các neo vector giả, nối hai chủ đề khác nhau về ngữ nghĩa nhưng tương tự về từ vựng.
              \item \emph{Phát hiện:} Quan trọng là, giao thức \textbf{LLM-làm-Giám-khảo} của chúng tôi đã đánh dấu lỗi này, gán Điểm Tính Nhất quán thấp \textbf{0,64} và \textbf{Tỷ lệ Thắng 0,00}. Điều này chứng minh khả năng của hệ thống tự động phát hiện suy giảm chất lượng để xem xét của con người.
          \end{itemize}
\end{enumerate}
