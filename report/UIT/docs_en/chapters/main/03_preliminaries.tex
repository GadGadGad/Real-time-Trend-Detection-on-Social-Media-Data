\chapter{Preliminaries}

\section{Large Language Models and Retrieval Augmented Generation}
Large Language Models (LLMs) such as GPT-4 and Gemini have revolutionized Natural Language Processing (NLP) by demonstrating emergent reasoning capabilities. Built upon the Transformer architecture \cite{ref_bert}, these models utilize self-attention mechanisms to capture long-range dependencies in textual data.
\begin{equation}
    Attention(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}
Despite their prowess, LLMs suffer from "hallucinations"â€”generating plausible but factually incorrect assertions. To mitigate this in domain-specific applications, Retrieval-Augmented Generation (RAG) is employed. RAG enhances the generative process by conditioning the LLM on retrieved relevant documents $D = \{d_1, ..., d_k\}$ before generating a response $y$:
\begin{equation}
    P(y|x) = \sum_{z \in D} P(z|x)P(y|x,z)
\end{equation}
In our system, we adapt this paradigm by treating "Clusters" as the retrieved context $z$, grounding the LLM's summarization in verified social data points.

\section{Stream Processing Architectures and Technologies}
Modern event detection requires handling data with high velocity and volume. To address this, the system adopts advanced technologies in big data and real-time stream processing.

\subsection{Kappa Architecture}
The \textbf{Kappa Architecture} simplifies the traditional Lambda Architecture by treating everything as a stream, eliminating the separate Batch Layer to reduce the complexity of maintaining dual codebases. This model relies on a robust message broker as an immutable log buffer, allowing data reprocessing (when logic changes) by replaying the stream from the beginning without a separate batch system.

\subsection{Apache Kafka}
Apache Kafka serves as the backbone of the Kappa architecture, functioning as a fault-tolerant distributed pub-sub messaging system.
In the system, Kafka is employed with the following mechanisms:
\begin{itemize}
    \item \textbf{Decoupling:} Separates data crawling modules (Producers) from the processing engine (Consumers/Spark), stabilizing the system during traffic spikes.
    \item \textbf{Log Storage:} Crawler data is serialized into JSON and pushed to \textbf{Topics} (e.g., \texttt{posts\_stream\_v1}). Topics are divided into \textbf{Partitions} to increase parallel write throughput. Consumers track reading positions via \textbf{offsets}, ensuring data integrity.
\end{itemize}
Consumption latency (Lag) is a critical metric for monitoring system health:
\begin{equation}
    \text{Lag}(t) = \text{Offset}_{produce}(t) - \text{Offset}_{consume}(t)
\end{equation}

\subsection{Apache Spark Structured Streaming}
\textbf{Spark Structured Streaming} is a stream processing engine built on Spark SQL, treating live data streams as an unbounded input table.
Its operation in the system includes:
\begin{itemize}
    \item \textbf{Micro-batching:} Processes streaming data in small batches (e.g., 200ms/batch). This allows applying Spark SQL engine optimizations (Catalyst Optimizer) to achieve high throughput.
    \item \textbf{Exactly-once Semantics:} Uses Checkpointing and Write-ahead Logs (WAL) to ensure each message is processed exactly once, even during system failures.
    \item \textbf{Pandas UDF:} Integrates with Python AI libraries (like PyTorch, Transformers) via User Defined Functions (UDF) to perform text vectorization directly on the data stream.
\end{itemize}

\subsection{Apache Airflow}
\textbf{Apache Airflow} is a workflow orchestration platform managing the Data Ingestion Layer.
Specific roles:
\begin{itemize}
    \item \textbf{DAG Management:} Crawler tasks are defined as Directed Acyclic Graphs (DAGs), enabling visualization of dependencies and execution flows.
    \item \textbf{Scheduling and Self-Healing:} Airflow schedules periodic runs (e.g., every 5 minutes) for crawlers and automatically retries failed tasks due to network errors or timeouts, ensuring continuous input data.
\end{itemize}

\section{Density-Based Clustering (HDBSCAN)}
Unlike centroid-based methods (K-Means) which assume spherical clusters, Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) \cite{ref_hdbscan} identifies clusters of varying densities and shapes.
HDBSCAN relies on a transformed distance metric to separate sparse noise from dense clusters. The \textbf{Core Distance} of a point $p$, denoted as $d_{core}(p)$, is defined as the distance to its $k$-th nearest neighbor. To ensure potential clusters are robust, the \textbf{Mutual Reachability Distance} between points $p$ and $q$ is formalized as:
\begin{equation}
    d_{mreach}(p, q) = \max \{ d_{core}(p), d_{core}(q), d(p, q) \}
\end{equation}
This metric effectively "pushes" sparse points away from each other. A Minimum Spanning Tree (MST) is then constructed using $d_{mreach}$ as edge weights. By iteratively removing edges with the highest weight, HDBSCAN builds a hierarchy of connected components, extracting stable clusters that persist over a wide range of density thresholds. This property is crucial for social media data, where event clusters ("Viral Trends") typically exhibit much higher density than background noise ("Daily Chatter").

\section{Event Taxonomy and Categorization}
To ensure actionable insights, we move beyond binary sentiment to a usage-based taxonomy (T1-T7), categorizing events by their value to specific stakeholders:

\begin{itemize}
    \item \textbf{T1. Crisis \& Public Risk} (Target: Emergency Services)\\
          \emph{Core Question: Is immediate intervention required?} Covers accidents, disasters, and riots.

    \item \textbf{T2. Policy Signal} (Target: Government)\\
          \emph{Core Question: How is the public reacting to new policies?} Covers new laws and official statements.

    \item \textbf{T3. Reputation Risk} (Target: PR Agencies)\\
          \emph{Core Question: Is public trust being damaged?} Covers scandals, boycotts, and controversies.

    \item \textbf{T4. Market Opportunity} (Target: Marketing Teams)\\
          \emph{Core Question: Is there monetizable demand?} Covers viral products and emerging lifestyle trends.

    \item \textbf{T5. Cultural Trend} (Target: Content Creators)\\
          \emph{Core Question: Is this trend worth riding for attention?} Covers memes and entertainment events.

    \item \textbf{T6. Operational Pain Point} (Target: Service Operators)\\
          \emph{Core Question: What are people complaining about?} Covers traffic, outages, and service failures.

    \item \textbf{T7. Routine/Noise} (Target: System Filter)\\
          \emph{Core Question: Should this be filtered?} Covers daily weather, routine sports, and lottery results.
\end{itemize}
