\section{Kiến thức Nền tảng}

\subsection{Các Mô hình Ngôn ngữ Lớn và Tạo sinh Tăng cường Truy xuất}
Các Mô hình Ngôn ngữ Lớn (LLM) như GPT-4 và Gemini đã cách mạng hóa Xử lý Ngôn ngữ Tự nhiên (NLP) bằng cách thể hiện khả năng suy luận phát sinh. Được xây dựng trên kiến trúc Transformer \cite{ref_bert}, các mô hình này sử dụng cơ chế self-attention để nắm bắt các phụ thuộc tầm xa trong dữ liệu văn bản.
\begin{equation}
    Attention(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}
Mặc dù có khả năng mạnh mẽ, LLMs mắc phải tình trạng ``ảo giác''---tạo ra các khẳng định có vẻ hợp lý nhưng thực tế không chính xác. Để giảm thiểu điều này trong các ứng dụng theo miền cụ thể, Tạo sinh Tăng cường Truy xuất (RAG) được sử dụng. RAG tăng cường quá trình tạo sinh bằng cách điều kiện hóa LLM trên các tài liệu liên quan được truy xuất $D = \{d_1, ..., d_k\}$ trước khi tạo phản hồi $y$:
\begin{equation}
    P(y|x) = \sum_{z \in D} P(z|x)P(y|x,z)
\end{equation}
Trong hệ thống của chúng tôi, chúng tôi điều chỉnh mô hình này bằng cách coi ``Các cụm'' là ngữ cảnh được truy xuất $z$, neo tóm tắt của LLM vào các điểm dữ liệu xã hội đã được xác minh.

\subsection{Các Kiến trúc Luồng Thời gian Thực}
Phát hiện sự kiện hiện đại đòi hỏi xử lý dữ liệu với tốc độ và khối lượng cao. \textbf{Kiến trúc Kappa} đơn giản hóa Kiến trúc Lambda truyền thống bằng cách coi mọi thứ như một luồng, sử dụng message broker dựa trên log mạnh mẽ như Apache Kafka.
Kafka phân vùng dữ liệu qua các broker phân tán, đảm bảo khả năng chịu lỗi và thông lượng cao. Consumers đọc dữ liệu từ các phân vùng này sử dụng offsets $O$, duy trì đảm bảo xử lý exactly-once:
\begin{equation}
    \text{Lag}(t) = \text{Offset}_{produce}(t) - \text{Offset}_{consume}(t)
\end{equation}
Để xử lý, \textbf{Spark Structured Streaming} coi các luồng dữ liệu trực tiếp như một bảng đầu vào không giới hạn. Nó xử lý dữ liệu văn bản theo micro-batches (ví dụ: khoảng 200ms), cho phép áp dụng các thao tác giống batch (như aggregations và joins) trên dữ liệu luồng với độ trễ tối thiểu.

\subsection{Phân cụm Dựa trên Mật độ (HDBSCAN)}
Khác với các phương pháp dựa trên centroid (K-Means) giả định các cụm hình cầu, Phân cụm Phân cấp Dựa trên Mật độ với Nhiễu (HDBSCAN) \cite{ref_hdbscan} xác định các cụm có mật độ và hình dạng khác nhau.
HDBSCAN dựa vào một metric khoảng cách được biến đổi để phân tách nhiễu thưa khỏi các cụm dày đặc. \textbf{Core Distance} của điểm $p$, ký hiệu là $d_{core}(p)$, được định nghĩa là khoảng cách đến lân cận thứ $k$. Để đảm bảo các cụm tiềm năng mạnh mẽ, \textbf{Mutual Reachability Distance} giữa các điểm $p$ và $q$ được hình thức hóa như:
\begin{equation}
    d_{mreach}(p, q) = \max \{ d_{core}(p), d_{core}(q), d(p, q) \}
\end{equation}
Metric này hiệu quả ``đẩy'' các điểm thưa ra xa nhau. Một Cây Bao trùm Tối thiểu (MST) sau đó được xây dựng sử dụng $d_{mreach}$ làm trọng số cạnh. Bằng cách lặp đi lặp lại loại bỏ các cạnh có trọng số cao nhất, HDBSCAN xây dựng một phân cấp các thành phần liên thông, trích xuất các cụm ổn định tồn tại qua một phạm vi rộng các ngưỡng mật độ. Thuộc tính này rất quan trọng cho dữ liệu mạng xã hội, nơi các cụm sự kiện (``Xu hướng Viral'') thường có mật độ cao hơn nhiều so với nhiễu nền (``Trò chuyện Hàng ngày'').

\subsection{Phân loại Sự kiện và Hệ thống Taxonomy}
Để đảm bảo các insight có thể hành động, chúng tôi vượt ra ngoài sentiment nhị phân đến một taxonomy dựa trên sử dụng (T1-T7), phân loại các sự kiện theo giá trị của chúng đối với các bên liên quan cụ thể:

\begin{itemize}
    \item \textbf{T1. Khủng hoảng \& Rủi ro Công cộng} (Đối tượng: Dịch vụ Khẩn cấp)\\
          \emph{Câu hỏi Cốt lõi: Có cần can thiệp ngay lập tức không?} Bao gồm tai nạn, thảm họa, và bạo loạn.

    \item \textbf{T2. Tín hiệu Chính sách} (Đối tượng: Chính phủ)\\
          \emph{Câu hỏi Cốt lõi: Công chúng phản ứng thế nào với các chính sách mới?} Bao gồm luật mới và tuyên bố chính thức.

    \item \textbf{T3. Rủi ro Danh tiếng} (Đối tượng: Cơ quan PR)\\
          \emph{Câu hỏi Cốt lõi: Niềm tin công chúng có bị tổn hại không?} Bao gồm scandal, tẩy chay, và tranh cãi.

    \item \textbf{T4. Cơ hội Thị trường} (Đối tượng: Đội ngũ Marketing)\\
          \emph{Câu hỏi Cốt lõi: Có nhu cầu có thể kiếm tiền không?} Bao gồm sản phẩm viral và xu hướng lối sống mới nổi.

    \item \textbf{T5. Xu hướng Văn hóa} (Đối tượng: Nhà sáng tạo Nội dung)\\
          \emph{Câu hỏi Cốt lõi: Xu hướng này có đáng theo để thu hút sự chú ý không?} Bao gồm meme và sự kiện giải trí.

    \item \textbf{T6. Điểm Đau Vận hành} (Đối tượng: Nhà Vận hành Dịch vụ)\\
          \emph{Câu hỏi Cốt lõi: Mọi người đang phàn nàn về điều gì?} Bao gồm giao thông, sự cố, và lỗi dịch vụ.

    \item \textbf{T7. Thường ngày/Nhiễu} (Đối tượng: Bộ lọc Hệ thống)\\
          \emph{Câu hỏi Cốt lõi: Có nên lọc điều này không?} Bao gồm thời tiết hàng ngày, thể thao thường xuyên, và kết quả xổ số.
\end{itemize}
