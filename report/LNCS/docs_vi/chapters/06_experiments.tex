\section{Dữ liệu và Thiết lập Thực nghiệm}

\subsection{Nguồn Dữ liệu}
Hệ thống của chúng tôi giám sát hai luồng dữ liệu chính, được thống nhất vào một schema chung để xử lý:
\begin{itemize}
    \item \textbf{Mạng Xã hội (Facebook):} Thu thập từ các Fanpage có tương tác cao (ví dụ: Theanh28, ThongTinChinhPhu). Các trường dữ liệu bao gồm: \texttt{pageName}, \texttt{postId}, \texttt{time} (ISO-8601), nội dung \texttt{text}, và các chỉ số tương tác (\texttt{likes}, \texttt{comments}, \texttt{shares}).
    \item \textbf{Tin tức Chính thống:} Các bài báo được crawl từ các nguồn đã xác minh (VnExpress, Tuổi Trẻ). Các trường chính: \texttt{ArticleID}, \texttt{URL}, \texttt{Title}, \texttt{Content}, và \texttt{PublishTime}.
    \item \textbf{Google Trends:} Các từ khóa tìm kiếm thời gian thực hoạt động như \textbf{tín hiệu xác nhận/trễ} để xác thực và ưu tiên các cụm ứng viên được phát hiện từ luồng xã hội.
\end{itemize}

Bộ dữ liệu thử nghiệm bao gồm \textbf{7.605 mục duy nhất} được thu thập từ 8 đến 22 tháng 12, 2025, bao gồm \textbf{4.644 bài báo tin tức được crawl} và \textbf{2.961 bài đăng mạng xã hội}.
Sau khi trích xuất nội dung, \textbf{4.603 bài báo tin tức} chứa văn bản body hợp lệ và được sử dụng cho neo và embedding. Ở đây, \textbf{2.961} biểu thị \emph{các bài đăng xã hội duy nhất được sử dụng trong thử nghiệm} sau khi khử trùng lặp và kiểm tra hợp lệ cơ bản (khối lượng crawl thô được báo cáo như một xấp xỉ).

\subsection{Phương pháp Thu thập Dữ liệu}
Để đảm bảo bao phủ toàn diện cảnh quan số Việt Nam, chúng tôi sử dụng chiến lược thu thập lai kết hợp các scraper tùy chỉnh và API bên thứ ba:

\begin{itemize}
    \item \textbf{Thu thập Bài báo Tin tức:} Chúng tôi phát triển các web scraper Python tùy chỉnh cho năm tờ báo Việt Nam lớn: VnExpress, Tuổi Trẻ, Thanh Niên, Người Lao Động và VietnamNet. Mỗi scraper triển khai:
          \begin{itemize}
              \item Khám phá bài báo đa luồng với pool worker có thể cấu hình
              \item Lọc theo khoảng thời gian cho thu thập lịch sử có mục tiêu
              \item Logic retry tự động với exponential backoff để đảm bảo độ bền
              \item Khử trùng lặp qua URL caching để cho phép crawl tăng dần
              \item Trích xuất có cấu trúc metadata (tiêu đề, tác giả, thời gian đăng, danh mục) và nội dung bài báo đầy đủ sử dụng BeautifulSoup
          \end{itemize}
          Các scraper được điều phối qua Apache Airflow DAGs, chạy theo lịch có thể cấu hình (mặc định: mỗi 6 giờ) để nắm bắt tin tức nóng trong khi tuân thủ rate limits.

    \item \textbf{Thu thập Mạng Xã hội:} Đối với các bài đăng công khai trên Facebook, chúng tôi sử dụng Apify\footnote{\url{https://apify.com/}}, một nền tảng web scraping dựa trên đám mây. Actor Facebook Pages Scraper của Apify được cấu hình để giám sát hơn 40 Fanpage Việt Nam có lưu lượng cao, trích xuất văn bản bài đăng, dấu thời gian và các chỉ số tương tác (likes, comments, shares). Phương pháp này đảm bảo tuân thủ điều khoản dịch vụ của nền tảng đồng thời cung cấp truy cập dữ liệu đáng tin cậy, có khả năng mở rộng mà không cần xác thực API trực tiếp.

    \item \textbf{Google Trends:} Các truy vấn tìm kiếm xu hướng thời gian thực cho Việt Nam được lấy qua unofficial Google Trends API wrapper, cung cấp tín hiệu xác nhận trễ cho ưu tiên hóa sự kiện.
\end{itemize}

\begin{figure}[ht]
    \centering
    \scalebox{0.75}{
        \begin{tikzpicture}[
            node distance=0.8cm and 1.2cm,
            box/.style={rectangle, draw, rounded corners, minimum width=2cm, minimum height=0.8cm, align=center, font=\small},
            source/.style={box, fill=blue!20},
            process/.style={box, fill=orange!20},
            storage/.style={box, fill=green!20},
            arrow/.style={-{Stealth[scale=0.8]}, thick}
            ]
            % Airflow Scheduler
            \node[process] (airflow) {Airflow\\Scheduler};

            % News Sources
            \node[source, right=1.5cm of airflow, yshift=1.6cm] (vne) {VnExpress};
            \node[source, right=1.5cm of airflow, yshift=0.8cm] (tt) {Tuổi Trẻ};
            \node[right=2.5cm of airflow, font=\large] (dots) {$\vdots$};
            \node[source, right=1.5cm of airflow, yshift=-0.8cm] (tn) {Thanh Niên};
            \node[source, right=1.5cm of airflow, yshift=-1.6cm] (nld) {NLD / VNN};

            % Scraper Workers
            \node[process, right=1.2cm of tt, yshift=-0.4cm] (workers) {Multi-Thread\\Workers};

            % Processing steps
            \node[process, right=1.2cm of workers] (extract) {HTML Parse\\+ Extract};
            \node[process, right=1.2cm of extract] (dedup) {Dedup\\Cache};

            % Storage
            \node[storage, right=1.2cm of dedup] (csv) {CSV / DB\\Storage};

            % Arrows
            \draw[arrow] (airflow) -- (vne);
            \draw[arrow] (airflow) -- (tt);
            \draw[arrow] (airflow) -- (tn);
            \draw[arrow] (airflow) -- (nld);

            \draw[arrow] (vne) -- (workers);
            \draw[arrow] (tt) -- (workers);
            \draw[arrow] (tn) -- (workers);
            \draw[arrow] (nld) -- (workers);

            \draw[arrow] (workers) -- (extract);
            \draw[arrow] (extract) -- (dedup);
            \draw[arrow] (dedup) -- (csv);

            % Retry loop
            \draw[arrow, dashed] (extract.south) -- ++(0,-0.5) -| node[pos=0.25, below, font=\scriptsize] {Retry} (workers.south);
        \end{tikzpicture}
    }
    \caption{Pipeline Thu thập Bài báo Tin tức.}
    \label{fig:news_pipeline}
\end{figure}

\noindent Hình \ref{fig:news_pipeline} minh họa quy trình thu thập bài báo tin tức. Mỗi thành phần đóng một vai trò cụ thể:
\begin{itemize}
    \item \textbf{Airflow Scheduler:} Apache Airflow điều phối các tác vụ crawl qua Directed Acyclic Graphs (DAGs). Mỗi nguồn tin tức có một DAG riêng được cấu hình chạy theo lịch 6 giờ, đảm bảo nắm bắt kịp thời tin tức nóng trong khi tránh quá tải máy chủ. Airflow cung cấp khả năng chịu lỗi, tự động retry và giám sát tập trung qua giao diện web.

    \item \textbf{Nguồn Tin tức (VnExpress, Tuổi Trẻ, Thanh Niên, NLD/VNN):} Đây là năm tờ báo Việt Nam lớn được nhắm đến bởi các scraper của chúng tôi. Mỗi nguồn có một triển khai scraper tùy chỉnh phù hợp với cấu trúc HTML và sơ đồ phân trang cụ thể của nó. Các scraper hỗ trợ cả crawl tăng dần (bài báo mới nhất) và thu thập lịch sử (truy vấn theo khoảng thời gian).

    \item \textbf{Multi-Thread Workers:} Mỗi scraper tạo một pool worker threads có thể cấu hình (mặc định: 10) để song song hóa các HTTP requests. Điều này giảm đáng kể tổng thời gian crawl trong khi tuân thủ rate limits thông qua request throttling. Workers sử dụng session chia sẻ với connection pooling để tăng hiệu quả.

    \item \textbf{HTML Parse + Extract:} Các phản hồi HTML thô được phân tích cú pháp sử dụng BeautifulSoup. Logic trích xuất là cụ thể theo nguồn, nhắm vào các phần tử có cấu trúc (ví dụ: \texttt{article-body}, \texttt{h1.title}) để trích xuất tiêu đề, tác giả, thời gian đăng, danh mục và nội dung bài báo đầy đủ. Các lần trích xuất thất bại kích hoạt cơ chế retry với exponential backoff.

    \item \textbf{Dedup Cache:} Một cache dựa trên URL (lưu trữ dưới dạng file local hoặc Redis) theo dõi các bài báo đã crawl trước đó. Trước khi xử lý, mỗi URL được kiểm tra với cache này để bỏ qua các bản sao, cho phép crawl tăng dần hiệu quả giữa các lần chạy.

    \item \textbf{CSV/DB Storage:} Các bài báo đã xác thực được lưu trữ dưới định dạng CSV để di động và tùy chọn chèn vào PostgreSQL cho truy vấn hạ nguồn. Mỗi bản ghi bao gồm tất cả metadata được trích xuất và văn bản bài báo đầy đủ.
\end{itemize}

\subsection{Phân tích Dữ liệu Khám phá}
Bảng \ref{tab:data_dist} trình bày phân phối bộ dữ liệu thử nghiệm của chúng tôi. Chúng tôi quan sát thấy một ``Khoảng cách Sẵn có'' đáng kể: trong khi chúng tôi crawl hơn 9.400 URL tin tức, chỉ \textbf{4.603 bài báo (48,6\%)} chứa văn bản body có thể trích xuất, trong khi \textbf{bài đăng mạng xã hội (2.961 mục)} đạt \emph{gần như hoàn toàn} về tính sẵn có.
Hơn nữa, có sự phân kỳ cấu trúc: Bài báo tin tức trung bình $>500$ từ với ngữ pháp chính thức, trong khi bài đăng xã hội trung bình $<50$ từ với tiếng lóng thường xuyên. Sự phân đôi này đòi hỏi thiết kế ``Hai Đường'' của chúng tôi, nơi \textbf{Fast Path} xử lý luồng xã hội văn bản ngắn, tốc độ cao, và \textbf{Slow Path} tận dụng LLMs để tổng hợp ngữ cảnh sâu hơn tìm thấy trong các neo tin tức.

\begin{table}
    \caption{Phân phối Dataset và Tính Sẵn có}\label{tab:data_dist}
    \centering
    \begin{tabular}{l c c c}
        \toprule
        \textbf{Loại Nguồn} & \textbf{URL Đã Crawl} & \textbf{Nội dung Hợp lệ} & \textbf{Độ dài TB (từ)} \\
        \midrule
        Tin tức Chính thống & $\approx 9.400$       & 4.603 (48,6\%)           & $> 500$                 \\
        Mạng Xã hội         & $\approx 3.000$       & 2.961 ($\approx 98,7\%$) & $< 50$                  \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Triển khai và Môi trường Vận hành}
Để đảm bảo tính tái lập và khả năng mở rộng, hệ thống được container hóa sử dụng \textbf{Docker Compose} với các dịch vụ cốt lõi sau:
\begin{itemize}
    \item \textbf{Ngăn xếp Phần mềm:} Apache Kafka 7.5.0, Apache Spark 3.5.0, PostgreSQL 15, MongoDB 6.0.
    \item \textbf{Phần cứng:} Tối ưu cho triển khai nút đơn (8GB RAM, 4 vCPUs) hoặc cụm Kubernetes.
    \item \textbf{Suy luận:} Tăng tốc ONNX Runtime trên GPU NVIDIA T4.
\end{itemize}

\subsubsection{Lợi ích Triển khai}
Kiến trúc microservices container hóa cung cấp ba lợi thế chính:
\begin{enumerate}
    \item \textbf{Khả năng Mở rộng:} Việc tách rời Thu nhập (Kafka) và Xử lý (Spark/LLM) cho phép mở rộng độc lập. Trong các sự kiện lưu lượng cao (ví dụ: bão), chúng tôi có thể thêm ngang các Spark Workers mà không cần cấu hình lại lớp thu nhập.
    \item \textbf{Hiệu quả Chi phí:} Bằng cách chuyển phân cụm batch nặng sang phần cứng hàng hóa cục bộ (CPU) và chỉ gọi API LLM trả phí cho các cụm đã xác minh (0,01\% khối lượng), chúng tôi giảm chi phí vận hành khoảng 400 lần so với các phương pháp dựa trên LLM thuần túy.
    \item \textbf{Tính Tái lập:} Toàn bộ ngăn xếp được định nghĩa trong \texttt{docker-compose.yml}, đảm bảo rằng môi trường ``Demo'' giống hệt ``Sản xuất'', loại bỏ vấn đề ``chạy được trên máy tôi''.
\end{enumerate}

\subsection{Dataset Construction Strategy}
To train our specialized models without incurring high labeling costs, we employed a \textbf{Hybrid Labeling Strategy}:
\begin{enumerate}
    \item \textbf{Học Tự giám sát:} Đối với Cross-Encoder Reranker, chúng tôi khai thác ``Hard Negatives'' (từ khóa tương tự nhưng ngữ nghĩa khác) để tạo 877 cặp chất lượng cao.
          Reranker này được sử dụng như thành phần khớp bổ trợ (xác minh / khôi phục) và như module benchmark offline.
    \item \textbf{Học Tích cực với LLM:} Đối với phân loại Sentiment và Taxonomy, chúng tôi sử dụng Gemini Pro để gán nhãn giả khoảng 10k mẫu, sau đó xem xét thủ công các điểm độ tin cậy thấp. Điều này mang lại \textbf{4.630 mẫu cho Sentiment} và \textbf{3.687 mẫu cho Taxonomy} huấn luyện.
\end{enumerate}

\begin{figure}[h]
    \centering
    \begin{verbatim}
{"text": "Vụ xả súng tại bãi biển Bondi khiến 15 người thiệt mạng.", 
 "label_sentiment": "Neutral", "label_taxonomy": "T1 - Crisis & Public Risk"}
{"text": ["Bão số 15 Koto đang ở đâu?", "Áp thấp nhiệt đới mạnh lên thành bão."], 
 "label_relevance": 1.0}
\end{verbatim}
    \caption{Ví dụ Dữ liệu Huấn luyện JSONL cho Phân loại và Reranking.} \label{fig:jsonl}
\end{figure}

\subsection{Lựa chọn Mô hình và Tinh chỉnh}
Chúng tôi tinh chỉnh các mô hình cụ thể cho tiếng Việt để phục vụ làm xương sống của hệ thống. Để đảm bảo tính mạnh mẽ, chúng tôi xây dựng một \textbf{Bộ Kiểm tra Stress} chứa 20 mẫu khó mỗi loại, đặc biệt nhắm vào các trường hợp biên như ``Tiếng lóng'' (ngôn ngữ mạng xã hội), ``Từ đồng nghĩa Bão'' (đặt tên sự kiện mơ hồ), và ``Chồng chéo Miền''. Bảng \ref{tab:training_config} chi tiết các siêu tham số huấn luyện cụ thể, và Bảng \ref{tab:models} hiển thị các metric hiệu suất cuối cùng trên bộ kiểm tra nghiêm ngặt này.

\begin{table}
    \caption{Cấu hình Huấn luyện Chi tiết và Siêu tham số}\label{tab:training_config}
    \centering
    \begin{tabular}{l l l l}
        \toprule
        \textbf{Mục tiêu Mô hình} & \textbf{Kiến trúc Cơ sở} & \textbf{Kích thước Dataset} & \textbf{Cấu hình Huấn luyện}    \\
        \midrule
        Sentiment                 & \texttt{uitnlp/visobert} & 4.630 (3 lớp)               & Epochs: 20, Batch: 32, LR: 2e-5 \\
        Taxonomy                  & \texttt{uitnlp/visobert} & 3.687 (7 lớp)               & Epochs: 20, Batch: 16, LR: 2e-5 \\
        Reranker                  & \texttt{ms-marco-MiniLM} & 877 cặp (Gold)              & Contractive Loss, Epochs: 20    \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/embedding_benchmark.png}
    \caption{Kết quả benchmark so sánh các Mô hình Embedding trên các trường hợp biên khác nhau.} \label{fig:benchmark}
\end{figure}



Hình \ref{fig:benchmark} so sánh độ ổn định (khoảng cách giữa cặp dương/âm) của 5 mô hình tiên tiến nhất. Chúng tôi định nghĩa Khoảng cách Ổn định theo toán học như:
\begin{equation}
    Gap = Sim(q, pos) - Sim(q, neg)
\end{equation}
\texttt{vietnamese-document-embedding} (thanh xanh) duy trì biên độ lớn nhất nhất quán trên các trường hợp biên như ``Từ đồng nghĩa Bão'' và ``Tiếng lóng'', xác nhận việc lựa chọn nó làm mô hình xương sống của chúng tôi.

Kết quả cho thấy \texttt{dangvantuan/vietnamese-document-embedding} đạt độ ổn định tốt nhất (Gap Trung bình 0,265). Bảng \ref{tab:embedding_benchmark} chi tiết hiệu suất trên các thách thức ngôn ngữ cụ thể, được định nghĩa như sau:

\begin{itemize}
    \item \textbf{Gap Trung bình:} Biên độ ổn định trung bình trên tất cả các trường hợp kiểm tra.
    \item \textbf{Bão:} Khả năng nhóm các tên bão đa dạng (ví dụ: ``Bão Yagi'', ``Bão số 3'').
    \item \textbf{Miền:} Truy xuất chéo miền (ví dụ: khớp truy vấn ``Y tế'' với bài đăng ``Bệnh viện'').
    \item \textbf{Danh mục:} Phân biệt giữa các loại sự kiện (ví dụ: ``Lũ lụt'' vs. ``Kẹt xe'').
    \item \textbf{Tiếng lóng:} Xử lý teen-code và tiếng lóng internet Việt Nam (ví dụ: ``bão'' vs ``b4o'').
    \item \textbf{Viết tắt:} Giải quyết các viết tắt phổ biến (ví dụ: ``HCM'' $\rightarrow$ ``Thành phố Hồ Chí Minh'').
\end{itemize}

\textbf{Phân tích:} Trong khi \texttt{vn-sbert} xuất sắc ở các nhiệm vụ nặng từ khóa như nhóm ``Bão'' (Gap: 0,355), nó thất bại hoàn toàn ở ``Tiếng lóng'' (-0,005), chỉ ra rằng nó coi tiếng lóng là nhiễu. Ngược lại, \texttt{vn-doc-embedding} duy trì hiệu suất mạnh mẽ trên ``Tiếng lóng'' (0,283) và ``Viết tắt'' (0,419), làm cho nó trở thành lựa chọn ưu việt để xử lý văn bản mạng xã hội thô nơi ngôn ngữ không chính thức phổ biến.

\begin{table}
    \caption{Embedding Stability Gap Analysis (Metric: Cosine Distance Diff)}\label{tab:embedding_benchmark}
    \centering
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{l c c c c c c}
            \toprule
            \textbf{Model Identifier}                   & \textbf{Avg Gap} $\uparrow$ & \textbf{Storm} $\uparrow$ & \textbf{Domain} $\uparrow$ & \textbf{Category} $\uparrow$ & \textbf{Slang}  $\uparrow$ & \textbf{Abbrev}  $\uparrow$ \\
            \midrule
            \textbf{vn-doc-embedding*} \cite{ref_vndoc} & \textbf{0.265}              & 0.239                     & 0.224                      & \textbf{0.162}               & \textbf{0.283}             & \textbf{0.419}              \\
            vn-bi-encoder                               & 0.193                       & 0.155                     & 0.213                      & 0.107                        & 0.108                      & 0.381                       \\
            vn-sbert \cite{ref_visobert}                & 0.188                       & \textbf{0.355}            & 0.172                      & 0.033                        & -0.005                     & 0.386                       \\
            bge-m3 \cite{ref_bge}                       & 0.160                       & -0.003                    & \textbf{0.269}             & 0.070                        & 0.192                      & 0.273                       \\
            multilingual-e5 \cite{ref_e5}               & 0.058                       & 0.018                     & 0.088                      & 0.022                        & 0.073                      & 0.091                       \\
            \bottomrule
        \end{tabular}%
    }
\end{table}

\begin{table}
    \caption{Hiệu suất Mô hình Đã Tinh chỉnh}\label{tab:models}
    \centering
    \begin{tabular}{l l c c}
        \toprule
        \textbf{Nhiệm vụ Mô hình} & \textbf{Loại Lớp}   & \textbf{Độ chính xác} ($\uparrow$) & \textbf{Độ trễ} ($\downarrow$) \\
        \midrule
        Bộ phân loại Sentiment    & 3 lớp (Pos/Neg/Neu) & \textbf{93,5\%}                    & 12ms                           \\
        Bi-CrossEncoder Reranker  & Xếp hạng Relevance  & 91,0\%                             & 45ms                           \\
        Bộ phân loại Taxonomy     & 7 lớp (T1-T7)       & 89,2\%                             & 14ms                           \\
        \bottomrule
    \end{tabular}
\end{table}
