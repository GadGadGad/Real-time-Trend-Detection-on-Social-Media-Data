{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Final Trend Detection Pipeline\n",
                "\n",
                "This notebook implements the complete pipeline for detecting real-time events from social media data, incorporating best practices for data processing and retrieval.\n",
                "\n",
                "### ‚ú® Key Improvements included:\n",
                "1.  **Title-based Embedding**: Solves length mismatch for News articles.\n",
                "2.  **Data Cleaning**: Removes OCR noise from Facebook posts.\n",
                "3.  **Hybrid Search**: Combines BM25 (Keyword) + Dense Retrieval (Semantic).\n",
                "4.  **Batch Summarization**: Optional step to summarize long content.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & Clone Repo\n",
                "!rm -rf Real-time-Event-Detection-on-Social-Media-Data  # Clean start\n",
                "!git clone https://github.com/GadGadGad/Real-time-Event-Detection-on-Social-Media-Data\n",
                "%cd Real-time-Event-Detection-on-Social-Media-Data\n",
                "!pip install -r requirements.txt -q\n",
                "!pip install -q rank_bm25 py_vncorenlp\n",
                "\n",
                "# VNCoreNLP Setup\n",
                "!mkdir -p vncorenlp_models\n",
                "!python3 -c \"import py_vncorenlp; py_vncorenlp.download_model(save_dir='vncorenlp_models')\"\n",
                "\n",
                "import sys\n",
                "import os\n",
                "import glob\n",
                "import json\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "from rich.console import Console\n",
                "from sentence_transformers import SentenceTransformer, util\n",
                "from rank_bm25 import BM25Okapi\n",
                "\n",
                "# Add project to path\n",
                "sys.path.append(os.getcwd())\n",
                "from src.pipeline.main_pipeline import load_social_data, load_news_data, load_google_trends\n",
                "from src.utils.text_processing.vectorizers import get_embeddings\n",
                "\n",
                "console = Console()\n",
                "print(\"‚úÖ Setup Complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Load Data\n",
                "# Paths are relative to the cloned repo root\n",
                "fb_files = glob.glob(\"crawlers/facebook/*.json\")\n",
                "news_files = glob.glob(\"crawlers/news/**/*.csv\", recursive=True)\n",
                "trend_files = glob.glob(\"crawlers/trendings/*.csv\")\n",
                "\n",
                "print(\"üìÇ Loading Data...\")\n",
                "posts = load_social_data(fb_files) + load_news_data(news_files)\n",
                "trends = load_google_trends(trend_files)\n",
                "\n",
                "print(f\"‚úÖ Loaded {len(posts)} posts and {len(trends)} trends.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üßπ 3. Data Cleaning & Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_facebook_content(text):\n",
                "    if not isinstance(text, str): return \"\"\n",
                "    noise_patterns = [\n",
                "        r\"May be an image of.*?\\n\",\n",
                "        r\"No photo description available.*?\\n\",\n",
                "        r\"\\+?\\d+ others\",\n",
                "        r\"Theanh28.*?\\n\",\n",
                "        r\"\\d+K likes\",\n",
                "        r\"\\d+ comments\"\n",
                "    ]\n",
                "    cleaned = text\n",
                "    for pattern in noise_patterns:\n",
                "        cleaned = re.sub(pattern, \"\", cleaned, flags=re.IGNORECASE)\n",
                "    return cleaned.strip()\n",
                "\n",
                "# CONFIG\n",
                "USE_TITLE_EMBEDDING = True  # Use Title for News, Content for FB\n",
                "EMBEDDING_CHAR_LIMIT = 300\n",
                "\n",
                "print(\"üßπ Cleaning and Preprocessing...\")\n",
                "processed_texts = []\n",
                "cleaned_count = 0\n",
                "\n",
                "for p in posts:\n",
                "    # 1. Clean FB Content\n",
                "    if p.get('source') == 'Facebook':\n",
                "        p['content'] = clean_facebook_content(p.get('content', ''))\n",
                "        cleaned_count += 1\n",
                "\n",
                "    # 2. Select Text for Embedding\n",
                "    text_to_embed = \"\"\n",
                "    if USE_TITLE_EMBEDDING:\n",
                "        # Use title if available and reasonable length (News)\n",
                "        title = p.get('title', '')\n",
                "        if title and len(str(title)) > 5:\n",
                "            text_to_embed = str(title)\n",
                "        else:\n",
                "            text_to_embed = p.get('content', '')\n",
                "    else:\n",
                "        text_to_embed = p.get('content', '')\n",
                "    \n",
                "    processed_texts.append(str(text_to_embed)[:EMBEDDING_CHAR_LIMIT])\n",
                "\n",
                "print(f\"‚úÖ Cleaned {cleaned_count} FB posts.\")\n",
                "print(f\"‚ÑπÔ∏è Using {'TITLES' if USE_TITLE_EMBEDDING else 'CONTENT'} for embedding.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß† 4. Hybrid Search Setup (BM25 + Dense)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_NAME = \"keepitreal/vietnamese-sbert\"\n",
                "print(\"‚öôÔ∏è Initializing Models...\")\n",
                "\n",
                "# 1. Initialize Dense Retrieval (SentenceTransformer)\n",
                "embedder = SentenceTransformer(MODEL_NAME)\n",
                "\n",
                "# 2. Initialize Sparse Retrieval (BM25)\n",
                "tokenized_corpus = [doc.split(\" \") for doc in processed_texts]\n",
                "bm25 = BM25Okapi(tokenized_corpus)\n",
                "\n",
                "# Hybrid Search Function\n",
                "def hybrid_search(query, top_k=5, alpha=0.5):\n",
                "    # Dense\n",
                "    query_emb = embedder.encode(query, convert_to_tensor=True)\n",
                "    # (In production, pre-compute corpus_embs!)\n",
                "    corpus_embs = embedder.encode(processed_texts, convert_to_tensor=True, show_progress_bar=False)\n",
                "    dense_scores = util.cos_sim(query_emb, corpus_embs)[0].cpu().numpy()\n",
                "    \n",
                "    # Sparse\n",
                "    tokenized_query = query.split(\" \")\n",
                "    sparse_scores = np.array(bm25.get_scores(tokenized_query))\n",
                "    if sparse_scores.max() > 0:\n",
                "        sparse_scores /= sparse_scores.max()\n",
                "        \n",
                "    # Combine\n",
                "    final_scores = alpha * dense_scores + (1 - alpha) * sparse_scores\n",
                "    \n",
                "    # Get Top K\n",
                "    top_indices = np.argsort(final_scores)[::-1][:top_k]\n",
                "    return [(i, final_scores[i]) for i in top_indices]\n",
                "\n",
                "print(\"‚úÖ Hybrid Search Ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST IT\n",
                "query = \"SEA Games 33\"\n",
                "results = hybrid_search(query, top_k=3)\n",
                "\n",
                "print(f\"üîç Top results for '{query}':\")\n",
                "for idx, score in results:\n",
                "    print(f\"[{score:.4f}] {processed_texts[idx]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù 5. Batch Summarization (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scripts.batch_summarize import batch_summarize\n",
                "\n",
                "# Only summarize if you need it later\n",
                "RUN_SUMMARIZATION = False\n",
                "\n",
                "if RUN_SUMMARIZATION:\n",
                "    print(\"Running batch summarization for FB posts...\")\n",
                "    fb_path = fb_files[0] if fb_files else None\n",
                "    if fb_path:\n",
                "        batch_summarize(\n",
                "            input_path=fb_path, \n",
                "            output_path='fb_summaries.json', \n",
                "            model_name='vit5-base', \n",
                "            resume=True\n",
                "        )"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}