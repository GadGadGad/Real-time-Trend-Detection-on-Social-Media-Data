{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.pipeline.main_pipeline import find_matches_hybrid, load_json, load_trends\n",
    "from src.utils.demo_state import save_demo_state\n",
    "\n",
    "# Configuration\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\") # Ensure this is set in your env\n",
    "THRESHOLD = 0.45\n",
    "USE_RRF = True\n",
    "RRF_K = 60\n",
    "USE_PRF = True\n",
    "USE_CACHE = True\n",
    "USE_NER = True\n",
    "MATCH_WEIGHTS = {'dense': 0.6, 'sparse': 0.4}\n",
    "EMBEDDING_CHAR_LIMIT = 500\n",
    "COHERENCE_THRESHOLD = 0.3\n",
    "DEBUG_LLM = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Paths\n",
    "post_files = [\n",
    "    'data/crawler/threads/threads_posts_20251221_194726.json',\n",
    "    'data/crawler/facebook/facebook_posts_20251221_194726.json'\n",
    "]\n",
    "trend_file = 'data/google_trends/news_trends_20251221.json'\n",
    "\n",
    "# Load data\n",
    "posts = []\n",
    "for f in post_files:\n",
    "    if os.path.exists(f):\n",
    "        posts.extend(load_json(f))\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: {f} not found.\")\n",
    "\n",
    "trends = load_trends(trend_file)\n",
    "print(f\"✅ Loaded {len(posts)} posts and {len(trends)} trends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064aa62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "matches, components = find_matches_hybrid(\n",
    "    posts=posts, \n",
    "    trends=trends, \n",
    "    use_llm=True, \n",
    "    gemini_api_key=GEMINI_API_KEY, \n",
    "    llm_provider='gemini',\n",
    "    min_cluster_size=10,\n",
    "    no_dedup=False,\n",
    "    debug_llm=DEBUG_LLM,\n",
    "    save_all=True,\n",
    "    embedding_char_limit=EMBEDDING_CHAR_LIMIT,\n",
    "    threshold=THRESHOLD,\n",
    "    use_rrf=USE_RRF,\n",
    "    rrf_k=RRF_K,\n",
    "    use_prf=USE_PRF,\n",
    "    use_cache=USE_CACHE,\n",
    "    use_ner=USE_NER,\n",
    "    coherence_threshold=COHERENCE_THRESHOLD,\n",
    "    match_weights=MATCH_WEIGHTS,\n",
    "    return_components=True\n",
    ")\n",
    "\n",
    "# Extract components\n",
    "trend_embeddings = components['trend_embeddings']\n",
    "post_embeddings = components['post_embeddings']\n",
    "cluster_labels = components['cluster_labels']\n",
    "cluster_mapping = components['cluster_mapping']\n",
    "MODEL_NAME = components['model_name']\n",
    "\n",
    "df_results = pd.DataFrame(matches)\n",
    "print(f\"✅ Pipeline completed. Found {len(df_results)} matches.\")\n",
    "df_results.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaac000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state for Streamlit Demo\n",
    "save_demo_state(\n",
    "    save_dir='demo_data',\n",
    "    df_results=df_results,\n",
    "    trends=trends,\n",
    "    trend_embeddings=trend_embeddings,\n",
    "    post_embeddings=post_embeddings,\n",
    "    cluster_labels=cluster_labels,\n",
    "    cluster_mapping=cluster_mapping,\n",
    "    model_name=MODEL_NAME,\n",
    "    metadata={\n",
    "        'threshold': THRESHOLD,\n",
    "        'run_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'use_rrf': USE_RRF,\n",
    "        'use_prf': USE_PRF\n",
    "    }\n",
    ")\n",
    "print(\"✅ Demo state saved to 'demo_data/'\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
