# Multi-Source Trend Detection and ANalysis System

Real-time trend detection tá»« multiple sources: Google Trends, Facebook, News sites.

## ðŸ“ Project Structure

```
â”œâ”€â”€ crawlers/                   # Core analysis modules
â”‚   â”œâ”€â”€ analyze_trends.py       # Main trend matching pipeline
â”‚   â”œâ”€â”€ evaluate_trends.py      # Visualization & scoring
â”‚   â”œâ”€â”€ alias_normalizer.py     # Text normalization with aliases
â”‚   â”œâ”€â”€ ner_extractor.py        # NER enrichment (optional)
â”‚   â”œâ”€â”€ trend_scoring.py        # G/F/N score calculator
â”‚   â”œâ”€â”€ vnexpress_crawler.py    # VNExpress news crawler
â”‚   â”œâ”€â”€ thanhnien_crawler.py    # Thanh Nien news crawler
â”‚   â””â”€â”€ facebook/               # Facebook page crawler
â”‚
â”œâ”€â”€ results/                    # Output files (gitignored)
â”‚   â”œâ”€â”€ results.json            # Matched trends data
â”‚   â”œâ”€â”€ trend_analysis.png      # Top trends chart
â”‚   â””â”€â”€ trend_tsne.png          # t-SNE visualization
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â””â”€â”€ kaggle_trend_analysis.ipynb  # Kaggle-ready notebook
â”‚
â”œâ”€â”€ data/                       # Crawled data storage
â”œâ”€â”€ flow.mmd                    # Pipeline flow diagram
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ run_crawlers.py             # Crawler orchestration
```

## Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
playwright install firefox
```

### 2. Run Trend Analysis

```bash
# Basic usage (alias normalization, recommended)
python crawlers/analyze_trends.py --output results.json

# With NER (alternative, requires underthesea)
python crawlers/analyze_trends.py --use-ner --output results.json

# Skip text enrichment
python crawlers/analyze_trends.py --no-aliases --output results.json
```

### 3. Evaluate & Visualize

```bash
# Default: Direct trend assignment (recommended)
python crawlers/evaluate_trends.py --input results.json

# Experimental: HDBSCAN clustering
python crawlers/evaluate_trends.py --input results.json --use-hdbscan

# Filter routine trends (weather, prices, etc.)
python crawlers/evaluate_trends.py --input results.json --filter-routine
```

## Pipeline Flow

```
Google Trends CSV â†’ Build Aliases â†’ Normalize Texts
                                         â†“
News + FB Posts â†’ Normalize â†’ Embed â†’ Match â†’ Valid Trends â†’ Score â†’ Classify
```

## Options

### analyze_trends.py

| Option | Default | Description |
|--------|---------|-------------|
| `--model` | `paraphrase-multilingual-mpnet-base-v2` | Embedding model |
| `--threshold` | `0.55` | Similarity threshold |
| `--use-ner` | `False` | Use NER instead of aliases |
| `--no-aliases` | `False` | Disable text normalization |
| `--save-all` | `False` | Include unmatched posts |

### evaluate_trends.py

| Option | Default | Description |
|--------|---------|-------------|
| `--min-posts` | `3` | Minimum posts for valid trend |
| `--use-hdbscan` | `False` | Use HDBSCAN clustering (experimental) |
| `--filter-routine` | `False` | Filter weather/price trends |

## Output

Each trend is scored and classified:

```json
{
  "trend": "CÃ´ng PhÆ°á»£ng",
  "Class": "Social-Driven",
  "Composite": 67.5,
  "G": 45, "F": 82, "N": 30,
  "posts": 156
}
```

**Classifications:**
- `Strong Multi-source`: High G + F + N
- `Social & News`: High F + N
- `Social-Driven`: High Facebook engagement
- `News-Driven`: High news coverage
- `Emerging`: Low scores across all

## Technical Notes

### Why Alias Normalization > NER?
- NER (underthesea) khÃ´ng nháº­n cÃ¡c tÃªn quá»‘c táº¿ (e.g., "Yagi")
- Alias uses Google Trends keywords â†’ higher match accuracy
- Test showed +16% improvement with aliases

### Why Direct Assignment > HDBSCAN?
- Data has 652+ small topics with no density peaks
- HDBSCAN classifies 84% as noise
- Direct trend assignment already provides meaningful clusters
